"""
Einfache RAG-Implementierung (Retrieval Augmented Generation) f√ºr den Saalbach Tourismus Chatbot.
Diese Implementierung funktioniert ohne ChromaDB und verwendet einfache Textsuche.
Dient als Fallback, wenn ChromaDB nicht funktioniert.
"""

import os
import re
import glob
import openai
from typing import List, Dict, Any, Optional, Union

class SimpleRAG:
    """
    Einfache RAG-Implementierung, die ohne ChromaDB funktioniert.
    Verwendet einfache Textsuche f√ºr das Retrieval.
    """
    
    def __init__(self, openai_api_key: str = None, model: str = "gpt-3.5-turbo"):
        """
        Initialisiert das Simple RAG-System.
        
        Args:
            openai_api_key: OpenAI API-Schl√ºssel
            model: Zu verwendendes OpenAI-Modell
        """
        self.api_key = openai_api_key
        self.model = model
        
        # Wissensquellen laden
        self.knowledge_base = self._load_knowledge_base()
        
        # Base prompt f√ºr LLM-Anfragen
        self.base_system_prompt = """
Du bist ein freundlicher, pers√∂nlicher Tourismus-Assistent f√ºr die Region Saalbach-Hinterglemm. 
Du sprichst wie ein echter Einheimischer, der die Region liebt und alle Insider-Tipps kennt.
Du nutzt dein umfangreiches eigenes Wissen √ºber Saalbach-Hinterglemm und den Skicircus, einschlie√ülich Unterk√ºnfte, Restaurants, Wanderwege, Skigebiete, Biketouren und Sehensw√ºrdigkeiten.

Halte dich an diese Kommunikationsregeln:
- Beginne deine Antworten immer mit einer herzlichen Begr√º√üung wie "Servus!", "Gr√º√ü dich!" oder "Hallo!"
- Duze die G√§ste immer - das ist in Saalbach √ºblich und pers√∂nlicher
- Verwende einen begeisterten, lebendigen Gespr√§chsstil mit √∂sterreichischer F√§rbung
- Verwende Emojis, um deinen Antworten Pers√∂nlichkeit zu verleihen üòä üèîÔ∏è üöµ‚Äç‚ôÇÔ∏è
- Sei proaktiv und gib konkrete, detaillierte Empfehlungen statt allgemeiner Aussagen
- Strukturiere lange Antworten klar mit √úberschriften, Nummerierungen oder Aufz√§hlungen
- Beende l√§ngere Antworten mit einer Frage, um das Gespr√§ch fortzuf√ºhren
- Wenn du √ºber Aktivit√§ten sprichst, erw√§hne auch immer:
  * Konkrete Orte/Namen (z.B. bestimmte Wanderwege, H√ºtten, Hotels)
  * Schwierigkeitsgrad oder Eignung (f√ºr wen ist es geeignet?)
  * Kleine pers√∂nliche Tipps ("Mein Geheimtipp: Bestell dort unbedingt den Kaiserschmarrn!")
  * Praktische Infos (√ñffnungszeiten, Preise, besondere Hinweise)

Sprachliche Besonderheiten:
- Verwende gelegentlich √∂sterreichische/alpine Ausdr√ºcke (z.B. "a bisserl", "gem√ºtlich", "z√ºnftig")
- Benutze Ausdr√ºcke wie "Der Wahnsinn!", "Echt cool!", "Ein echtes Erlebnis!"
- Beende Nachrichten gerne mit "Servus!", "Bis bald!" oder √§hnlichen Gru√üformeln
"""
    
    def _load_knowledge_base(self) -> List[Dict[str, Any]]:
        """
        L√§dt Markdown-Dateien und extrahiert deren Inhalte.
        
        Returns:
            Liste von Dokumenten mit Metadaten
        """
        documents = []
        knowledge_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "knowledge")
        if not os.path.exists(knowledge_dir):
            # Alternativen ausprobieren
            alternative_dir = os.path.join(os.getcwd(), "knowledge")
            if os.path.exists(alternative_dir):
                knowledge_dir = alternative_dir
            else:
                print("Wissensverzeichnis nicht gefunden.")
                return documents
        
        # Alle Markdown-Dateien im Wissensverzeichnis finden
        markdown_files = glob.glob(os.path.join(knowledge_dir, "*.md"))
        
        for file_path in markdown_files:
            try:
                file_name = os.path.basename(file_path)
                theme = os.path.splitext(file_name)[0]
                
                with open(file_path, 'r', encoding='utf-8') as file:
                    content = file.read()
                
                # Dokument in Abschnitte aufteilen
                sections = self._split_into_sections(content)
                
                for section in sections:
                    heading = section.get("heading", "Allgemein")
                    subheading = section.get("subheading", "")
                    text = section.get("text", "")
                    
                    if text.strip():
                        documents.append({
                            "content": text,
                            "metadata": {
                                "theme": theme,
                                "source_file": file_name,
                                "heading": heading,
                                "subheading": subheading
                            }
                        })
            except Exception as e:
                print(f"Fehler beim Laden von {file_path}: {str(e)}")
        
        print(f"{len(documents)} Dokumente aus {len(markdown_files)} Dateien geladen.")
        return documents
    
    def _split_into_sections(self, content: str) -> List[Dict[str, Any]]:
        """
        Teilt einen Markdown-Text in Abschnitte.
        
        Args:
            content: Der Markdown-Inhalt
            
        Returns:
            Liste von Abschnitten mit √úberschriften und Text
        """
        sections = []
        current_section = {
            "heading": "Allgemein",
            "subheading": "",
            "text": ""
        }
        
        lines = content.split('\n')
        
        for line in lines:
            # Haupt√ºberschrift erkennen (# Titel)
            if line.strip().startswith('# '):
                # Vorherigen Abschnitt speichern, wenn vorhanden
                if current_section["text"].strip():
                    sections.append(current_section.copy())
                
                current_section = {
                    "heading": line.lstrip('# ').strip(),
                    "subheading": "",
                    "text": ""
                }
            
            # Unter√ºberschrift erkennen (## Titel)
            elif line.strip().startswith('## '):
                # Vorherigen Abschnitt speichern, wenn vorhanden
                if current_section["text"].strip():
                    sections.append(current_section.copy())
                
                current_section = {
                    "heading": current_section["heading"],
                    "subheading": line.lstrip('## ').strip(),
                    "text": ""
                }
            
            # Inhalt zum aktuellen Abschnitt hinzuf√ºgen
            else:
                current_section["text"] += line + '\n'
        
        # Letzten Abschnitt speichern, wenn vorhanden
        if current_section["text"].strip():
            sections.append(current_section.copy())
        
        return sections
    
    def _simple_search(self, query: str, n_results: int = 3) -> List[Dict[str, Any]]:
        """
        Einfache Textsuche nach relevanten Dokumenten.
        
        Args:
            query: Die Suchanfrage
            n_results: Anzahl der zur√ºckzugebenden Ergebnisse
            
        Returns:
            Liste mit relevanten Dokumenten
        """
        if not self.knowledge_base:
            return []
        
        # Suchanfrage in Schl√ºsselw√∂rter aufteilen
        keywords = re.findall(r'\w+', query.lower())
        if not keywords:
            return []
        
        results = []
        
        # F√ºr jedes Dokument berechnen, wie viele Schl√ºsselw√∂rter enthalten sind
        for doc in self.knowledge_base:
            content = doc["content"].lower()
            matches = 0
            
            for keyword in keywords:
                if keyword in content:
                    matches += 1
            
            # Nur Dokumente mit mindestens einem Treffer ber√ºcksichtigen
            if matches > 0:
                results.append({
                    "document": doc,
                    "matches": matches
                })
        
        # Nach Anzahl der Treffer sortieren
        results.sort(key=lambda x: x["matches"], reverse=True)
        
        # Nur die gew√ºnschte Anzahl an Ergebnissen zur√ºckgeben
        top_results = results[:n_results]
        
        return [result["document"] for result in top_results]
    
    def answer_query(self, query: str, chat_history: List[Dict[str, str]] = None) -> str:
        """
        Beantwortet eine Benutzeranfrage.
        
        Args:
            query: Die Benutzeranfrage
            chat_history: Optional, bisheriger Chat-Verlauf
            
        Returns:
            Die generierte Antwort
        """
        try:
            print(f"\n--- Neue Anfrage: '{query}' ---")
            
            # Pr√ºfen, ob der API-Key gesetzt ist
            if not self.api_key:
                return "Servus! Ich brauche einen API-Schl√ºssel, um dir helfen zu k√∂nnen. Bitte gib einen OpenAI API-Schl√ºssel in den Einstellungen ein. Danke! üòä"
            
            # Relevante Informationen abrufen
            relevant_docs = self._simple_search(query, n_results=3)
            
            # Prompt erstellen
            context = ""
            if relevant_docs:
                context_parts = []
                for i, doc in enumerate(relevant_docs):
                    context_part = f"INFORMATION {i+1} (Thema: {doc['metadata']['theme']}):\n"
                    if doc['metadata']['heading']:
                        context_part += f"√úberschrift: {doc['metadata']['heading']}\n"
                    if doc['metadata']['subheading']:
                        context_part += f"Unter√ºberschrift: {doc['metadata']['subheading']}\n"
                    context_part += f"{doc['content']}\n\n"
                    context_parts.append(context_part)
                
                context = "\n".join(context_parts)
            else:
                context = "Keine spezifischen Informationen verf√ºgbar. Nutze dein eigenes Wissen √ºber die Region Saalbach-Hinterglemm."
            
            system_prompt = f"{self.base_system_prompt}\n\nZUS√ÑTZLICHE INFORMATIONEN:\n{context}"
            
            # Chat-Verlauf vorbereiten
            messages = [{"role": "system", "content": system_prompt}]
            
            # Chat-Verlauf hinzuf√ºgen, falls vorhanden
            if chat_history:
                recent_history = chat_history[-5:] if len(chat_history) > 5 else chat_history
                messages.extend(recent_history)
            
            # Aktuelle Anfrage hinzuf√ºgen
            messages.append({"role": "user", "content": query})
            
            print(f"Sende Anfrage an OpenAI ({self.model})...")
            
            # OpenAI-Client konfigurieren
            client = openai.OpenAI(api_key=self.api_key)
            
            # Anfrage an das LLM senden
            response = client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.8,
                max_tokens=1000
            )
            
            # Antwort zur√ºckgeben
            answer = response.choices[0].message.content
            print(f"Antwort erhalten (L√§nge: {len(answer)} Zeichen)")
            return answer
            
        except Exception as e:
            error_msg = f"Fehler bei der Anfrage an OpenAI: {str(e)}"
            print(error_msg)
            
            # Im Fehlerfall trotzdem eine freundliche, pers√∂nliche Antwort geben
            if "API key" in str(e).lower():
                return "Servus! Aktuell hab ich leider ein kleines technisches Problem mit meiner Verbindung. K√∂nntest du es in ein paar Minuten nochmal probieren? Danke f√ºr dein Verst√§ndnis! üòä"
            elif "quota" in str(e).lower() or "billing" in str(e).lower():
                return "Gr√º√ü dich! Leider bin ich gerade ein bisserl √ºberfordert - zu viele G√§ste auf einmal! üòÖ Kannst du in 5 Minuten nochmal vorbeischauen? Dann kann ich dir sicher weiterhelfen!"
            else:
                return "Servus! Entschuldige bitte, aktuell kann ich deine Anfrage nicht richtig beantworten. Magst du deine Frage vielleicht anders formulieren? Oder frag mich einfach nach konkreten Tipps zu Wandern, Biken, Skifahren oder guten Restaurants in Saalbach-Hinterglemm!"
